{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfFpLw4YLyg2"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "During this class section we will be make a dataset (suprise suprise) by folowing this notebook. We will scrape data off of [https://money.com/best-colleges/](https://money.com/best-colleges/). Money is an independent, advertiser-supported website and their editors \"research hundreds of sources and contact hundreds of the most respected experts in each industry to get the most relevant information to help others make the right purchasing decision.\" The data consists of various/useful metrics of the the best colleges in America ranked by value (as determined by the website). \n",
    "\n",
    "We will follow the steps of the web scraping \"pipeline\" in this notebook.\n",
    "\n",
    "Features of the dataset - Demo\n",
    "\n",
    "First lets explore the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebuJ1B1gNCA0"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X81PeRmbLRUh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an GET request to get all the html from this webpage, print out the status code and the server that is giving you the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the html document into a beautiful soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ8TFIU4Njkd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code cell to define this simple function. What is this function doing? What are we going to use it? What type of object does `element` have to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTVfIls61KAo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above function and find the proper CSS Selectors to get the respective data, I will demo the first one. Note that getting CSS selectors can be tricky. I usually like to do a combo of the SelectorGadget extension and the Inspect Element tool to determine proper selectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhBR7thPNsxF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data from the table stored into their respective lists, we can move onto getting data specific to the college by \"clicking\" on the link in the table. How do be \"click\" links on a webpage with `requests` and `BeautifulSoup`? Implement it below by \"clicking\" on the \"University of Michigan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fph-bTsOJoJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I initialized a bunch of lists that will store data specific to a college. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0s15oAtvfoI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Click\" on each link and extract the proper data (make sure to find and use the right CSS Selectors) and then add them to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtichZE3s8bm"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus in a few week is on the `pandas` package which is what we will use to store the data we extract from a webpage. I have made the code to package all the data into a dataset and save it as a `.csv` file. You will understand how I am doing at a later time, for now just know that the code beow exports everything as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pandas if you havent already\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqUTenVuzqtH"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"college_names\": college_names, \n",
    "    \"college_location\": college_location, \n",
    "    \"overall_score\" : overall_score,\n",
    "    \"acceptance_rate\" : acceptance_rate,\n",
    "    \"Est_full_price_22_23\": Est_full_price_22_23, \n",
    "    \"Est_price_with_avg_grant\": Est_price_with_avg_grant, \n",
    "    \"percent_of_student_who_get_grants\": percent_of_student_who_get_grants, \n",
    "    \"graduation_rate\": graduation_rate,\n",
    "    \"early_career_earnings\": early_career_earnings,\n",
    "    \"avg_price_for_low_income_students\": avg_price_for_low_income_students,\n",
    "    \"median_sat_act_score\" : median_sat_act_score,\n",
    "    \"sat_act_required\" : sat_act_required,\n",
    "    \"undergrad_enrollment\": undergrad_enrollment, \n",
    "    \"percent_of_students_with_need_who_get_grants\" : percent_of_students_with_need_who_get_grants,\n",
    "    \"percent_of_need_met\" : percent_of_need_met,\n",
    "    \"percent_of_students_who_get_merit_grants\" : percent_of_students_who_get_merit_grants, \n",
    "    \"avg_merit_grant\" : avg_merit_grant,\n",
    "    \"avg_time_to_a_degree\" : avg_time_to_a_degree,\n",
    "    \"median_student_debt\" : median_student_debt,\n",
    "    \"percent_earning_more_than_a_high_school_grad\" : percent_earning_more_than_a_high_school_grad \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUzeTyL40jnK"
   },
   "outputs": [],
   "source": [
    "college_df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "fDws5BrX0py1",
    "outputId": "51f6ed0f-1f69-436c-a4e8-037645a34279"
   },
   "outputs": [],
   "source": [
    "college_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the shape of the dataset, we have 623 rows and 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibko-bmK5aOY",
    "outputId": "0a1d2443-e47a-4919-92a0-72280e2a52ff"
   },
   "outputs": [],
   "source": [
    "college_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_df.to_csv(\"Dataset_on_colleges.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "STAT 4185 - WebScraping_In_Class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 22:45:29) [MSC v.1916 32 bit (Intel)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3877f4da012a59f5a6e1a5615d8dfc8bcec5744beb86635a1dc99cfdc65a7c72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
